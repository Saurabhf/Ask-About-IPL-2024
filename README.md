### Overview:
This repository contains a Jupyter Notebook file showcasing a Retrieval-Augmented Generation (RAG) implementation using an open-source Large Language Model (LLM) i.e LLAMA2. The setup integrates Pinecone for storing vector embeddings and LangChain for retrieving the most relevant answers to user queries based on provided documents.  

### Features:
1. Open-Source LLM: Utilizes a powerful open-source large language model LLAMA2 to generate responses.
2. Pinecone Integration: Stores document vector embeddings in Pinecone for fast and efficient retrieval.
3. LangChain: Leverages LangChain to retrieve the most relevant documents and provide answers for queries.
